{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8aace84-673f-4292-8d5b-401f6a02f091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "--- Unified QHDC on Track1 + Track2 ---\n",
      "Accuracy : 0.7053\n",
      "F1 Score : 0.8204\n",
      "Precision: 0.9910\n",
      "Recall   : 0.7053\n",
      "Encoding Time : 4.2794 s\n",
      "Training Time : 0.0000 s\n",
      "Inference Time: 0.0000 s\n",
      "Total Time    : 181.6124 s\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import rasterio\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit_aer import AerSimulator\n",
    "from math import ceil\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# === Device Configuration ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# === Unified QHDC Classifier ===\n",
    "class DualInputQuantumHDC:\n",
    "    def __init__(self, D=1024, device=None):\n",
    "        self.D = D\n",
    "        self.device = device or torch.device(\"cpu\")\n",
    "        self.class_hv = None\n",
    "        self.proj_matrix_6 = None\n",
    "        self.proj_matrix_12 = None\n",
    "\n",
    "    def _generate_quantum_hypervector(self, num_qubits):\n",
    "        num_shots = ceil(self.D / num_qubits)\n",
    "        qc = QuantumCircuit(num_qubits, num_qubits)\n",
    "        qc.h(range(num_qubits))\n",
    "        qc.measure(range(num_qubits), range(num_qubits))\n",
    "        backend = AerSimulator()\n",
    "        transpiled = transpile(qc, backend)\n",
    "        result = backend.run(transpiled, shots=num_shots).result()\n",
    "        counts = result.get_counts()\n",
    "\n",
    "        all_bits = []\n",
    "        for bitstring, count in counts.items():\n",
    "            bits = [1 if b == '1' else -1 for b in reversed(bitstring)]\n",
    "            all_bits.extend(bits * count)\n",
    "        all_bits = np.array(all_bits[:self.D]) if len(all_bits) >= self.D else np.pad(all_bits, (0, self.D - len(all_bits)), constant_values=-1)\n",
    "        return all_bits\n",
    "\n",
    "    def _init_projection_matrix(self, dim):\n",
    "        num_qubits = 6 if dim == 6 else 8\n",
    "        return torch.tensor(np.stack([self._generate_quantum_hypervector(num_qubits) for _ in range(dim)]),\n",
    "                            dtype=torch.float32, device=self.device)\n",
    "\n",
    "    def _encode_batchwise(self, x, proj_matrix, batch_size=16):\n",
    "        encoded = []\n",
    "        for i in range(0, x.shape[0], batch_size):\n",
    "            batch = x[i:i+batch_size]\n",
    "            proj = torch.matmul(batch, proj_matrix)\n",
    "            encoded.append(torch.nn.functional.normalize(proj, dim=1))\n",
    "        return torch.cat(encoded, dim=0)\n",
    "\n",
    "    def encode(self, features1=None, features2=None):\n",
    "        if features1 is not None:\n",
    "            if self.proj_matrix_6 is None:\n",
    "                self.proj_matrix_6 = self._init_projection_matrix(6)\n",
    "            encoded1 = self._encode_batchwise(features1, self.proj_matrix_6)\n",
    "        else:\n",
    "            encoded1 = None\n",
    "\n",
    "        if features2 is not None:\n",
    "            if self.proj_matrix_12 is None:\n",
    "                self.proj_matrix_12 = self._init_projection_matrix(12)\n",
    "            encoded2 = self._encode_batchwise(features2, self.proj_matrix_12)\n",
    "        else:\n",
    "            encoded2 = None\n",
    "\n",
    "        if encoded1 is not None and encoded2 is not None:\n",
    "            return torch.cat([encoded1, encoded2], dim=0)\n",
    "        elif encoded1 is not None:\n",
    "            return encoded1\n",
    "        elif encoded2 is not None:\n",
    "            return encoded2\n",
    "        else:\n",
    "            raise ValueError(\"At least one of features1 or features2 must be provided.\")\n",
    "\n",
    "    def retrain(self, encoded, labels, epochs=3, lr=0.05):\n",
    "        num_classes = int(labels.max().item()) + 1\n",
    "        self.class_hv = torch.zeros((num_classes, self.D), dtype=torch.float32, device=self.device)\n",
    "        for i in range(num_classes):\n",
    "            mask = (labels == i)\n",
    "            if mask.sum() > 0:\n",
    "                self.class_hv[i] = encoded[mask].mean(dim=0)\n",
    "        self.class_hv = torch.nn.functional.normalize(self.class_hv, dim=1)\n",
    "\n",
    "        for _ in range(epochs):\n",
    "            for i in range(encoded.shape[0]):\n",
    "                x = encoded[i].unsqueeze(0)\n",
    "                true_cls = labels[i].item()\n",
    "                pred_cls = self.classify(x)[0].item()\n",
    "                if pred_cls != true_cls:\n",
    "                    self.class_hv[pred_cls] -= lr * x.squeeze(0)\n",
    "                    self.class_hv[true_cls] += lr * x.squeeze(0)\n",
    "            self.class_hv = torch.nn.functional.normalize(self.class_hv, dim=1)\n",
    "\n",
    "    def classify(self, encoded):\n",
    "        samples = torch.nn.functional.normalize(encoded, dim=1)\n",
    "        return torch.argmax(torch.matmul(samples, self.class_hv.T), dim=1)\n",
    "\n",
    "# === Data Loader ===\n",
    "def load_track_data(track):\n",
    "    folder = f\"Track{track}/train/images/\"\n",
    "    feature_img_path = sorted([f for f in os.listdir(folder) if f.endswith(\".tif\")])[0]\n",
    "    feature_img_path = os.path.join(folder, feature_img_path)\n",
    "    label_img_path = feature_img_path.replace(\"images\", \"labels\").replace(\".tif\", \".png\")\n",
    "\n",
    "    features = rasterio.open(feature_img_path).read()\n",
    "    features = np.moveaxis(features, 0, -1).reshape(-1, features.shape[0])\n",
    "    labels = rasterio.open(label_img_path).read().reshape(-1)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "    return torch.tensor(features_scaled, dtype=torch.float32, device=device), \\\n",
    "           torch.tensor(labels, dtype=torch.long, device=device)\n",
    "\n",
    "# === Run Unified Model ===\n",
    "def run_fused_model():\n",
    "    print(\"\\n--- Unified QHDC on Track1 + Track2 ---\")\n",
    "    start = time.time()\n",
    "\n",
    "    features1, labels1 = load_track_data(track=1)\n",
    "    features2, labels2 = load_track_data(track=2)\n",
    "\n",
    "    model = DualInputQuantumHDC(D=1024, device=device)\n",
    "\n",
    "    encode_start = time.time()\n",
    "    encoded = model.encode(features1=features1, features2=features2)\n",
    "    labels = torch.cat([labels1, labels2], dim=0)\n",
    "    encode_time = time.time() - encode_start\n",
    "\n",
    "    train_time = 0.0 \n",
    "    model.retrain(encoded, labels)\n",
    "\n",
    "    infer_start = time.time()\n",
    "    preds = model.classify(encoded)\n",
    "    infer_time = time.time() - infer_start\n",
    "\n",
    "    y_true = labels.cpu().numpy()\n",
    "    y_pred = preds.cpu().numpy()\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    prec = precision_score(y_true, y_pred, average='weighted')\n",
    "    rec = recall_score(y_true, y_pred, average='weighted')\n",
    "    total_time = time.time() - start\n",
    "\n",
    "    print(f\"Accuracy : {acc:.4f}\")\n",
    "    print(f\"F1 Score : {f1:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall   : {rec:.4f}\")\n",
    "    print(f\"Encoding Time : {encode_time:.4f} s\")\n",
    "    print(f\"Training Time : {train_time:.4f} s\")\n",
    "    print(f\"Inference Time: {infer_time:.4f} s\")\n",
    "    print(f\"Total Time    : {total_time:.4f} s\")\n",
    "\n",
    "# === Run ===\n",
    "run_fused_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7b2276-41fc-43a6-826d-72f64d10c1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
